{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "facial-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "taken-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "feng_trainning_set = '/usr/src/tp2-1/data-in/210301_feng_Train_TP2_Datos_2020-2C.csv'\n",
    "feng_eval_set = '/usr/src/tp2-1/data-in/210301_feng_Test_TP2_Datos_2020-2C.csv'\n",
    "\n",
    "train_source_file = feng_trainning_set\n",
    "test_source_file = feng_eval_set\n",
    "\n",
    "kaggle_predict_file =  '/usr/src/tp2-1/data-out/2100301_random_forest_TimeSeriesSplit.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainning_set = '/usr/src/tp2-1/data-in/Train_TP2_Datos_2020-2C.csv'\n",
    "eval_set = '/usr/src/tp2-1/data-in/Test_TP2_Datos_2020-2C.csv'\n",
    "\n",
    "feng_trainning_set = '/usr/src/tp2-1/data-in/210301_feng_Train_TP2_Datos_2020-2C.csv'\n",
    "feng_eval_set = '/usr/src/tp2-1/data-in/210301_feng_Test_TP2_Datos_2020-2C.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-beatles",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convinced-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_df(df, onehotencoder = None):\n",
    "    \n",
    "    # drops -------------------------------------------------\n",
    "    '''\n",
    "      removemos la columna de la cual el modelo podria aprender que su existencia\n",
    "      implica el Closed_won (ya que es un valor que se obtiene a posteriori de haber\n",
    "      ganado y estaria mal usarlo ya que los modelos entrenadas con ella serian \n",
    "      incapaces de poder predecir correctamente)\n",
    "    '''\n",
    "    df = df.drop(['Sales_Contract_No'], axis=1)\n",
    "    \n",
    "    # N/R\n",
    "    df = df.drop(['ID'], axis=1)\n",
    "    \n",
    "    # dato cte = NaT\n",
    "    df = df.drop(['Last_Activity'], axis=1)\n",
    "    \n",
    "    # esta columna es equivalente a oportunity_id\n",
    "    df = df.drop(['Opportunity_Name'], axis=1)\n",
    "    \n",
    "    # basado en lo charlado con el grupo, ahora subdividimos el df de forma de tener\n",
    "    # en cuenta los casos cerrados y cobertimos las varaibles categorias en su\n",
    "    # representacion mas simple (siendo dos casos en Cloased_Won = 1 y Closed:_lost = 0)\n",
    "    if 'Stage' in df.columns:\n",
    "        df = df[((df['Stage'] == 'Closed Won') | (df['Stage'] == 'Closed Lost'))]\n",
    "        df['Stage'] = df['Stage'].apply(lambda x: 1 if x == 'Closed Won' else 0)\n",
    "    \n",
    "    my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_rx = pd.DataFrame(my_imputer.fit_transform(df))\n",
    "    df_rx.columns = df.columns\n",
    "    df = df_rx \n",
    "    \n",
    "    # Total_Taxable_Amount = Sum rows[Total_Amount]\n",
    "\n",
    "    numeric_cols = ['Opportunity_ID', 'TRF', 'ASP', 'ASP_(converted)', 'Total_Amount', 'Total_Taxable_Amount']\n",
    "    if 'Stage' in df.columns:\n",
    "        numeric_cols.append('Stage')\n",
    "    else:\n",
    "        print('no la agrego!')\n",
    "        \n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n",
    "    \n",
    "    df['Last_Modified_Date'] = pd.to_datetime(df['Last_Modified_Date'], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    def get_factor_estim_periodo(currency, date_in_row):\n",
    "        \n",
    "        \n",
    "        date_window_begin = date_in_row - timedelta(days=30)\n",
    "        date_window_end = date_in_row + timedelta(days=30)\n",
    "        #print('buscando para: ', currency, date_in_row, date_window_begin, date_window_end)\n",
    "        \n",
    "        mask = ((df['Last_Modified_Date'] >= date_window_begin) | (df['Last_Modified_Date'] >= date_window_end)) & (df['ASP_Currency'] == currency) & (df['ASP_max'] > 0)\n",
    "        #mask = (df['Last_Modified_Date'] > date_window_begin) & (df['Last_Modified_Date'] <= date_window_end)\n",
    "        sdf = df.loc[mask]\n",
    "        factor = sdf['ASP_(converted)_max'].mean() / sdf['ASP_max'].mean() \n",
    "        #print(factor, sdf['ASP_(converted)_max'].mean(), sdf['ASP_max'].mean() )\n",
    "        #print(sdf[['ASP_Currency', 'ASP_(converted)_max', 'ASP_max']].head(10))\n",
    "        #sub_df = df.loc[interval:'ASP_max']\n",
    "        #print(sub_df)\n",
    "        #print(sub_df.mean)\n",
    "        \n",
    "        \n",
    "        # busca el valor pronedio de asp y asp_convert para $currency\n",
    "        # dentro de una cierta ventana de tiempo entorno a $date_in_row\n",
    "        \n",
    "        return factor\n",
    "        \n",
    "        #mask = (df['date'] > start_date) & (df['date'] <= end_date)\n",
    "        #df.loc[mask]\n",
    "        \n",
    "    def define_factor(a, b, currency, date_in_row):\n",
    "        if (a == 0) or (a == np.nan) or  (b == 0) or (b == np.nan):\n",
    "            return get_factor_estim_periodo(currency, date_in_row)\n",
    "        else:\n",
    "            return a / b\n",
    "        \n",
    "    '''\n",
    "    if ((row['ASP_max'] == 0) | (row['ASP_max'] == np.nan)):\n",
    "            return -1\n",
    "        else:\n",
    "            return row[\"ASP_(converted)_max\"] / row[\"ASP_max\"]\n",
    "    ''' \n",
    "        \n",
    "    # preparamos la columna Total_Taxable_Amount para ser aplanada\n",
    "    df[\"Total_Amount_sum\"] = df.groupby(\"Opportunity_ID\")[\"Total_Amount\"].transform(\"sum\")\n",
    "    \n",
    "    df[\"ASP_max\"] = df.groupby(\"Opportunity_ID\")[\"ASP\"].transform(\"max\")\n",
    "    df[\"ASP_(converted)_max\"] = df.groupby(\"Opportunity_ID\")[\"ASP_(converted)\"].transform(\"max\")\n",
    "    \n",
    "    df[\"rel_cnv_currency\"] = df.apply(lambda x: define_factor(x[\"ASP_(converted)_max\"], x['ASP_max'], x['ASP_Currency'], x['Last_Modified_Date']) , axis=1)\n",
    "    \n",
    "\n",
    "    df = df.drop(['ASP'], axis=1)\n",
    "    df = df.drop(['ASP_(converted)'], axis=1)\n",
    "    \n",
    "    #return df, OneHotEncoder(handle_unknown = 'ignore')\n",
    "    \n",
    "    \n",
    "    #df[\"rel_cnv_currency\"] = df[\"ASP_(converted)_max\"] / df[\"ASP_max\"]\n",
    "    \n",
    "    # @todo hay un solo registro que queda anomalo, eliminarlo\n",
    "    #  >>> df.loc[df_train['ASP_(converted)'] / df['ASP'] > 2, :] = 0\n",
    "    \n",
    "    \n",
    "    #df = df.drop(['Total_Taxable_Amount'], axis=1)\n",
    "    #df = df.drop(['Total_Amount_Currency'], axis=1)\n",
    "    df[\"Total_Amount_sum_usd\"] = df[\"rel_cnv_currency\"] * df[\"Total_Amount_sum\"]\n",
    "    df = df.drop(['Total_Amount_sum'], axis=1)\n",
    "    df[\"Total_Amount_usd\"] = df[\"rel_cnv_currency\"] * df[\"Total_Amount\"]\n",
    "    df = df.drop(['Total_Amount'], axis=1)\n",
    "    df[\"Total_Taxable_Amount_usd\"] = df[\"rel_cnv_currency\"] * df[\"Total_Taxable_Amount\"]\n",
    "    df = df.drop(['Total_Taxable_Amount'], axis=1)\n",
    "    \n",
    "    df = df.drop(['Total_Amount_Currency'], axis=1)\n",
    "    df = df.drop(['Total_Taxable_Amount_Currency'], axis=1)\n",
    "    df = df.drop(['ASP_Currency'], axis=1)\n",
    "    df = df.drop(['ASP_(converted)_Currency'], axis=1)\n",
    "    \n",
    "    \n",
    "    #return df, OneHotEncoder(handle_unknown = 'ignore')\n",
    "   \n",
    "    \n",
    "    # todo: convertir estas en una ventana de tiempo\n",
    "    df['Planned_Delivery_Start_Date'] = pd.to_datetime(df['Planned_Delivery_Start_Date'], format=\"%m/%d/%Y\")\n",
    "    df['Planned_Delivery_End_Date'] = pd.to_datetime(df['Planned_Delivery_End_Date'], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    df['Planned_Delivery_Date_diff'] = (df['Planned_Delivery_End_Date'] - df['Planned_Delivery_Start_Date']).dt.days\n",
    "    \n",
    "    df = df.drop(['Planned_Delivery_Start_Date'], axis=1)\n",
    "    df = df.drop(['Planned_Delivery_End_Date'], axis=1)\n",
    "    \n",
    "    # @todo: no estoy seguro si esto aporta\n",
    "    df = df.drop(['Quote_Expiry_Date'], axis=1)\n",
    "    \n",
    "    # @todo: convertirla a una diferencia de dias?\n",
    "    df = df.drop(['Last_Modified_Date'], axis=1)\n",
    "    \n",
    "    # hacemos que las variables temporales en las que nos vanos a enfocar sean del tipo correcto\n",
    "    df['Account_Created_Date'] = pd.to_datetime(df['Account_Created_Date'], format=\"%m/%d/%Y\")\n",
    "    df['Opportunity_Created_Date'] = pd.to_datetime(df['Opportunity_Created_Date'], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    df['Quote_Type'] = df['Quote_Type'].apply(lambda x: 1 if x == 'Binding' else 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #------------------------------------------\n",
    "    df = df.sort_values(by=\"Opportunity_Created_Date\")\n",
    "    \n",
    "    df = df.drop(columns = 'Opportunity_Created_Date')\n",
    "    df = df.drop(columns = 'Account_Created_Date')\n",
    "    #------------------------------------------\n",
    "    \n",
    "    # df = df.drop(4907, axis = 0)\n",
    "    # ndf.loc[ndf.rel_cnv_currency > 2,:]\n",
    "\n",
    "    \n",
    "    numeric_cols_rv = ['ASP_max', 'ASP_(converted)_max', 'rel_cnv_currency', \n",
    "                       'Total_Amount_sum_usd', 'Total_Amount_usd', 'Total_Taxable_Amount_usd', 'Planned_Delivery_Date_diff', 'Opportunity_ID']\n",
    "    if 'Stage' in df.columns:\n",
    "        numeric_cols.append('Stage')\n",
    "    \n",
    "    df[numeric_cols_rv] = df[numeric_cols_rv].apply(pd.to_numeric)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    #df[numeric_cols_rv] = df[numeric_cols_rv].apply(pd.to_numeric)\n",
    "    #df.dropna()\n",
    "    \n",
    "    #return df, OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "    categoric_cols = df.columns[df.dtypes==object].tolist() \n",
    "    numeric_cols = df.columns[df.dtypes=='float64'].tolist() \n",
    "    numeric_cols_2 = df.columns[df.dtypes=='int64'].tolist() \n",
    "    date_cols = df.columns[df.dtypes=='datetime64[ns]'].tolist() \n",
    "\n",
    "    \n",
    "    if 'Stage' in df.columns:\n",
    "        onehotencoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "        onehotencoder.fit(df[categoric_cols])\n",
    "    \n",
    "    cat_rel = 0\n",
    "    all_col_names = []\n",
    "    for cat in onehotencoder.categories_:\n",
    "        for col in cat:\n",
    "            all_col_names.append(categoric_cols[cat_rel] + '_' + str(col))\n",
    "        cat_rel = cat_rel + 1\n",
    "    \n",
    "    categorical = pd.DataFrame(onehotencoder.transform(df[categoric_cols]).toarray(), columns=all_col_names)\n",
    "    \n",
    "    categorical = categorical.reset_index()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    frames_to_concat = [categorical, df[numeric_cols], df[numeric_cols_2]]\n",
    "    df_r =  pd.concat(frames_to_concat, axis=1)\n",
    "       \n",
    "    df_r = df_r.drop(columns = 'index')\n",
    "    \n",
    "    #@todo sigue dando problemas este campo armado: Planned_Delivery_Date_diff\n",
    "    df_r = df_r.fillna(0)\n",
    "    \n",
    "    return df_r, onehotencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dried-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(trainning_set )\n",
    "\n",
    "# como vamos a hacer un merge, no queremos perder filas solo por que\n",
    "# alguna posicion tiene algun dato faltante\n",
    "# df_train = df_train.fillna(0) >>>  @todo revisar que pasa con esto, lo resuleve el xgboost o lo normalizo antes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exotic-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "consecutive-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.loc[df_train['ASP_(converted)'] / df_train['ASP'] > 1.5, ['ASP', 'ASP_(converted)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "whole-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASP', 'ASP_(converted)', 'Total_Amount']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train.info()\n",
    "cols_with_missing = [col for col in df_train.columns\n",
    "                     if df_train[col].isnull().any()]\n",
    "\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "leading-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[['ASP', 'ASP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outer-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.loc[df_train['Opportunity_ID'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wicked-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ndf, onehotencoder] = normaliza_df(df_train)\n",
    "\n",
    "#ndf = ndf.drop(4907, axis = 0)\n",
    "#ndf.loc[ndf.rel_cnv_currency > 2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "strong-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "optimum-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train.info()\n",
    "cols_with_missing = [col for col in ndf.columns\n",
    "                     if ndf[col].isnull().any()]\n",
    "\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "registered-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndf.dtypes\n",
    "#ndf.describe()\n",
    "#ndf.loc[ndf.ASP_max == 0, :]\n",
    "#ndf.Total_Amount_Currency.value_counts()\n",
    "\n",
    "#asp_val = (ndf.loc[ndf.Total_Amount_Currency == 'EUR','ASP_max']).mean()\n",
    "#asp_cnv_val = (ndf.loc[ndf.Total_Amount_Currency == 'EUR','ASP_(converted)_max']).mean()\n",
    "#ndf.loc[ndf['Opportunity_ID'] == 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "comfortable-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf2 = ndf.groupby('Opportunity_ID').max()\n",
    "ndf2 = ndf2.reset_index()\n",
    "#ndf2 = df.drop(columns = 'Opportunity_ID')\n",
    "#ndf2 = ndf2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "needed-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9791, 2865)\n"
     ]
    }
   ],
   "source": [
    "print(ndf2.shape)\n",
    "#ndf2 = ndf2.dropna()\n",
    "#print(ndf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mysterious-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf2.to_csv(feng_trainning_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-charlotte",
   "metadata": {},
   "source": [
    "# proceso el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reported-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no la agrego!\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(eval_set)\n",
    "[ndft, _] = normaliza_df(df_test, onehotencoder)\n",
    "\n",
    "ndft2 = ndft.groupby('Opportunity_ID').max()\n",
    "ndft2 = ndft2.reset_index()\n",
    "\n",
    "print(ndft2.shape)\n",
    "\n",
    "ndft2.to_csv(feng_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-message",
   "metadata": {},
   "source": [
    "# ahora si juego con el set para ver un poco mas la relacion entre features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polar-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guarda con esto que altera el Set (por eso lo grabe antes)\n",
    "X = ndf2\n",
    "y = X.pop('Stage')\n",
    "ID = X.pop('Opportunity_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "actual-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region_APAC</th>\n",
       "      <th>Region_Americas</th>\n",
       "      <th>Region_EMEA</th>\n",
       "      <th>Region_Japan</th>\n",
       "      <th>Region_Middle East</th>\n",
       "      <th>Territory_Albania</th>\n",
       "      <th>Territory_Armenia</th>\n",
       "      <th>Territory_Australia</th>\n",
       "      <th>Territory_Austria</th>\n",
       "      <th>Territory_Belarus</th>\n",
       "      <th>...</th>\n",
       "      <th>Prod_Category_A_Prod_Category_A_None</th>\n",
       "      <th>ASP_max</th>\n",
       "      <th>ASP_(converted)_max</th>\n",
       "      <th>rel_cnv_currency</th>\n",
       "      <th>Total_Amount_sum_usd</th>\n",
       "      <th>Total_Amount_usd</th>\n",
       "      <th>Total_Taxable_Amount_usd</th>\n",
       "      <th>Planned_Delivery_Date_diff</th>\n",
       "      <th>Quote_Type</th>\n",
       "      <th>TRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9791.0</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9.791000e+03</td>\n",
       "      <td>9.791000e+03</td>\n",
       "      <td>9.791000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.212338</td>\n",
       "      <td>0.250434</td>\n",
       "      <td>0.330610</td>\n",
       "      <td>0.192524</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.058932</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.365970</td>\n",
       "      <td>0.451011</td>\n",
       "      <td>0.872219</td>\n",
       "      <td>1.719144e+06</td>\n",
       "      <td>1.359723e+06</td>\n",
       "      <td>1.621077e+06</td>\n",
       "      <td>29.946584</td>\n",
       "      <td>0.013277</td>\n",
       "      <td>3.133184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.408984</td>\n",
       "      <td>0.433285</td>\n",
       "      <td>0.470457</td>\n",
       "      <td>0.394302</td>\n",
       "      <td>0.117887</td>\n",
       "      <td>0.014292</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.235509</td>\n",
       "      <td>0.085442</td>\n",
       "      <td>0.017503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.551504</td>\n",
       "      <td>0.894175</td>\n",
       "      <td>0.388130</td>\n",
       "      <td>8.459134e+06</td>\n",
       "      <td>7.339129e+06</td>\n",
       "      <td>1.599115e+07</td>\n",
       "      <td>703.568543</td>\n",
       "      <td>0.114466</td>\n",
       "      <td>14.838808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008866</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.730625e+04</td>\n",
       "      <td>4.189500e+04</td>\n",
       "      <td>2.850000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.277966e+05</td>\n",
       "      <td>1.075900e+05</td>\n",
       "      <td>1.031093e+05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.494470</td>\n",
       "      <td>1.131086</td>\n",
       "      <td>5.139525e+05</td>\n",
       "      <td>4.527174e+05</td>\n",
       "      <td>4.034625e+05</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.318056</td>\n",
       "      <td>3.150001e+08</td>\n",
       "      <td>3.150001e+08</td>\n",
       "      <td>1.356339e+09</td>\n",
       "      <td>69474.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 2863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Region_APAC  Region_Americas  Region_EMEA  Region_Japan  \\\n",
       "count  9791.000000      9791.000000  9791.000000   9791.000000   \n",
       "mean      0.212338         0.250434     0.330610      0.192524   \n",
       "std       0.408984         0.433285     0.470457      0.394302   \n",
       "min       0.000000         0.000000     0.000000      0.000000   \n",
       "25%       0.000000         0.000000     0.000000      0.000000   \n",
       "50%       0.000000         0.000000     0.000000      0.000000   \n",
       "75%       0.000000         1.000000     1.000000      0.000000   \n",
       "max       1.000000         1.000000     1.000000      1.000000   \n",
       "\n",
       "       Region_Middle East  Territory_Albania  Territory_Armenia  \\\n",
       "count         9791.000000        9791.000000        9791.000000   \n",
       "mean             0.014095           0.000204           0.000102   \n",
       "std              0.117887           0.014292           0.010106   \n",
       "min              0.000000           0.000000           0.000000   \n",
       "25%              0.000000           0.000000           0.000000   \n",
       "50%              0.000000           0.000000           0.000000   \n",
       "75%              0.000000           0.000000           0.000000   \n",
       "max              1.000000           1.000000           1.000000   \n",
       "\n",
       "       Territory_Australia  Territory_Austria  Territory_Belarus  ...  \\\n",
       "count          9791.000000        9791.000000        9791.000000  ...   \n",
       "mean              0.058932           0.007354           0.000306  ...   \n",
       "std               0.235509           0.085442           0.017503  ...   \n",
       "min               0.000000           0.000000           0.000000  ...   \n",
       "25%               0.000000           0.000000           0.000000  ...   \n",
       "50%               0.000000           0.000000           0.000000  ...   \n",
       "75%               0.000000           0.000000           0.000000  ...   \n",
       "max               1.000000           1.000000           1.000000  ...   \n",
       "\n",
       "       Prod_Category_A_Prod_Category_A_None      ASP_max  ASP_(converted)_max  \\\n",
       "count                                9791.0  9791.000000          9791.000000   \n",
       "mean                                    1.0     9.365970             0.451011   \n",
       "std                                     0.0    21.551504             0.894175   \n",
       "min                                     1.0     0.000000             0.000000   \n",
       "25%                                     1.0     0.370000             0.380000   \n",
       "50%                                     1.0     0.410000             0.420000   \n",
       "75%                                     1.0     0.530000             0.494470   \n",
       "max                                     1.0    80.000000            67.000000   \n",
       "\n",
       "       rel_cnv_currency  Total_Amount_sum_usd  Total_Amount_usd  \\\n",
       "count       9791.000000          9.791000e+03      9.791000e+03   \n",
       "mean           0.872219          1.719144e+06      1.359723e+06   \n",
       "std            0.388130          8.459134e+06      7.339129e+06   \n",
       "min            0.008866          0.000000e+00      0.000000e+00   \n",
       "25%            1.000000          4.730625e+04      4.189500e+04   \n",
       "50%            1.000000          1.277966e+05      1.075900e+05   \n",
       "75%            1.131086          5.139525e+05      4.527174e+05   \n",
       "max            1.318056          3.150001e+08      3.150001e+08   \n",
       "\n",
       "       Total_Taxable_Amount_usd  Planned_Delivery_Date_diff   Quote_Type  \\\n",
       "count              9.791000e+03                 9791.000000  9791.000000   \n",
       "mean               1.621077e+06                   29.946584     0.013277   \n",
       "std                1.599115e+07                  703.568543     0.114466   \n",
       "min                0.000000e+00                    0.000000     0.000000   \n",
       "25%                2.850000e+04                    0.000000     0.000000   \n",
       "50%                1.031093e+05                    6.000000     0.000000   \n",
       "75%                4.034625e+05                   28.000000     0.000000   \n",
       "max                1.356339e+09                69474.000000     1.000000   \n",
       "\n",
       "               TRF  \n",
       "count  9791.000000  \n",
       "mean      3.133184  \n",
       "std      14.838808  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max     500.000000  \n",
       "\n",
       "[8 rows x 2863 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "approved-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "challenging-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total_Amount_usd                         0.176835\n",
       "Total_Amount_sum_usd                     0.152148\n",
       "Total_Taxable_Amount_usd                 0.137605\n",
       "TRF                                      0.126928\n",
       "ASP_(converted)_max                      0.087657\n",
       "Planned_Delivery_Date_diff               0.079384\n",
       "ASP_max                                  0.071614\n",
       "Product_Type_None                        0.052618\n",
       "Currency_None                            0.049277\n",
       "rel_cnv_currency                         0.049158\n",
       "Brand_None                               0.048605\n",
       "Opportunity_Type_Opportunity_Type_19     0.044689\n",
       "Account_Type_Account_Type_0              0.038647\n",
       "Bureaucratic_Code_Bureaucratic_Code_4    0.037544\n",
       "Product_Category_B_None                  0.037537\n",
       "Price_None                               0.036565\n",
       "Size_None                                0.036172\n",
       "Size_Other                               0.035658\n",
       "Bureaucratic_Code_Bureaucratic_Code_5    0.033828\n",
       "Price_Other                              0.032830\n",
       "Opportunity_Type_Opportunity_Type_7      0.031183\n",
       "Brand_Other                              0.031104\n",
       "Size_Size_3                              0.028090\n",
       "Account_Name_Account_Name_1662           0.026849\n",
       "Account_Name_Account_Name_594            0.026582\n",
       "Account_Name_Account_Name_1293           0.025962\n",
       "Account_Name_Account_Name_2063           0.025892\n",
       "Account_Type_Account_Type_5              0.025343\n",
       "Account_Name_Account_Name_1972           0.024998\n",
       "Product_Category_B_Other                 0.024682\n",
       "Bureaucratic_Code_0_Approval_1           0.024223\n",
       "Account_Name_Account_Name_393            0.024140\n",
       "Bureaucratic_Code_0_Approval_0           0.024101\n",
       "Territory_Solomon Islands                0.022546\n",
       "Account_Name_Account_Name_84             0.022404\n",
       "Currency_USD                             0.022172\n",
       "Product_Name_Product_Name_502            0.021964\n",
       "Account_Name_Account_Name_1470           0.021423\n",
       "Account_Name_Account_Name_111            0.020974\n",
       "Product_Type_Other                       0.020875\n",
       "Product_Family_Product_Family_19         0.020762\n",
       "Account_Name_Account_Name_1508           0.020592\n",
       "Price_0.28                               0.020573\n",
       "Product_Name_Product_Name_500            0.020236\n",
       "Product_Name_Product_Name_445            0.020179\n",
       "Account_Name_Account_Name_789            0.020176\n",
       "Product_Name_Product_Name_339            0.020058\n",
       "Opportunity_Owner_Person_Name_19         0.019938\n",
       "Product_Name_Product_Name_149            0.019881\n",
       "Last_Modified_By_Person_Name_13          0.019778\n",
       "Name: MI Scores, dtype: float64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "residential-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total_Amount_usd', 'Total_Amount_sum_usd', 'Total_Taxable_Amount_usd',\n",
       "       'TRF', 'ASP_(converted)_max', 'Planned_Delivery_Date_diff', 'ASP_max',\n",
       "       'Product_Type_None', 'Currency_None', 'rel_cnv_currency', 'Brand_None',\n",
       "       'Opportunity_Type_Opportunity_Type_19', 'Account_Type_Account_Type_0',\n",
       "       'Bureaucratic_Code_Bureaucratic_Code_4', 'Product_Category_B_None',\n",
       "       'Price_None', 'Size_None', 'Size_Other',\n",
       "       'Bureaucratic_Code_Bureaucratic_Code_5', 'Price_Other',\n",
       "       'Opportunity_Type_Opportunity_Type_7', 'Brand_Other', 'Size_Size_3',\n",
       "       'Account_Name_Account_Name_1662', 'Account_Name_Account_Name_594',\n",
       "       'Account_Name_Account_Name_1293', 'Account_Name_Account_Name_2063',\n",
       "       'Account_Type_Account_Type_5', 'Account_Name_Account_Name_1972',\n",
       "       'Product_Category_B_Other', 'Bureaucratic_Code_0_Approval_1',\n",
       "       'Account_Name_Account_Name_393', 'Bureaucratic_Code_0_Approval_0',\n",
       "       'Territory_Solomon Islands', 'Account_Name_Account_Name_84',\n",
       "       'Currency_USD', 'Product_Name_Product_Name_502',\n",
       "       'Account_Name_Account_Name_1470', 'Account_Name_Account_Name_111',\n",
       "       'Product_Type_Other', 'Product_Family_Product_Family_19',\n",
       "       'Account_Name_Account_Name_1508', 'Price_0.28',\n",
       "       'Product_Name_Product_Name_500', 'Product_Name_Product_Name_445',\n",
       "       'Account_Name_Account_Name_789', 'Product_Name_Product_Name_339',\n",
       "       'Opportunity_Owner_Person_Name_19', 'Product_Name_Product_Name_149',\n",
       "       'Last_Modified_By_Person_Name_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores.nlargest(50).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "dominant-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feat = ['Total_Amount_usd', 'Total_Amount_sum_usd', 'Total_Taxable_Amount_usd',\n",
    "       'TRF', 'Planned_Delivery_Date_diff', 'Product_Type', 'rel_cnv_currency', 'Brand',\n",
    "       'Opportunity_Type_Opportunity_Type', 'Account_Type',\n",
    "       'Bureaucratic_Code', 'Product_Category_B_None',\n",
    "       'Price_None', 'Size_None', 'Size_Other', 'Price_Other',\n",
    "       'Size_Size_3',\n",
    "       'Account_Name',\n",
    "       'Product_Category_B_Other', 'Bureaucratic_Code_0_Approval',\n",
    "       'Account_Name',\n",
    "       'Territory', 'Account_Name_Account_Name_84',\n",
    "       'Currency_USD', 'Product_Name',\n",
    "       'Account_Name_Account_Name_1470', 'Account_Name_Account_Name_111',\n",
    "       'Product_Family_Product_Family_19',\n",
    "       'Account_Name', 'Price_0.28',\n",
    "       'Opportunity_Owner_Person_Name', \n",
    "       'Last_Modified_By_Person_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "rational-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "annoying-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9791, 2863)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "rotary-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing = [col for col in ndf2.columns\n",
    "                     if ndf2[col].isnull().any()]\n",
    "\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "removed-capitol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
