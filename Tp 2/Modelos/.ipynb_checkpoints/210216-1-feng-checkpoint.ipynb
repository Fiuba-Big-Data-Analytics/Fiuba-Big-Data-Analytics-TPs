{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodeamos todas los features categoricos usando One Hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza_df(df, ones_hots):\n",
    "    # inicialmente voy con el tratamiento mas simple sobre los datos faltantes\n",
    "    df = df.fillna(0)\n",
    "    df = df.dropna()\n",
    "    '''\n",
    "      removemos la columna de la cual el modelo podria aprender que su existencia\n",
    "      implica el Closed_won (ya que es un valor que se obtiene a posteriori de haber\n",
    "      ganado y estaria mal usarlo ya que los modelos entrenadas con ella serian \n",
    "      incapaces de poder predecir correctamente)\n",
    "    '''\n",
    "    df = df.drop(['Sales_Contract_No'], axis=1)\n",
    "    \n",
    "    # irrelevantes\n",
    "    df = df.drop(['Opportunity_Name'], axis=1)\n",
    "\n",
    "    # dato cte = NaT\n",
    "    df = df.drop(['Last_Activity'], axis=1)\n",
    "\n",
    "    # basado en lo charlado con el grupo, ahora subdividimos el df de forma de tener\n",
    "    # en cuenta los casos cerrados y cobertimos las varaibles categorias en su\n",
    "    # representacion mas simple (siendo dos casos en Cloased_Won = 1 y Closed:_lost = 0)\n",
    "    if 'Stage' in df.columns:\n",
    "        df = df[((df['Stage'] == 'Closed Won') | (df['Stage'] == 'Closed Lost'))]\n",
    "        df['Stage'] = df['Stage'].apply(lambda x: 1 if x == 'Closed Won' else 0)\n",
    "    \n",
    "    # hacemos que las variables temporales en las que nos vanos a enfocar sean del tipo correcto\n",
    "    df['Account_Created_Date'] = pd.to_datetime(df['Account_Created_Date'], format=\"%m/%d/%Y\")\n",
    "    df['Opportunity_Created_Date'] = pd.to_datetime(df['Opportunity_Created_Date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "    df['Quote_Type'] = df['Quote_Type'].apply(lambda x: 1 if x == 'Binding' else 0)\n",
    "    \n",
    "    # todo: convertir estas en una ventana de tiempo\n",
    "    df = df.drop(['Planned_Delivery_Start_Date'], axis=1)\n",
    "    df = df.drop(['Planned_Delivery_End_Date'], axis=1)\n",
    "\n",
    "    categoric_cols = df.columns[df.dtypes==object].tolist() \n",
    "    numeric_cols = df.columns[df.dtypes=='float64'].tolist() \n",
    "    numeric_cols_2 = df.columns[df.dtypes=='int64'].tolist() \n",
    "    date_cols = df.columns[df.dtypes=='datetime64[ns]'].tolist() \n",
    "    \n",
    "    print(categoric_cols)\n",
    "    print('--------------')\n",
    "    \n",
    "    \n",
    "    def crearOneHotDF(c1):\n",
    "        if 'Stage' in df.columns:\n",
    "            onehotencoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "            onehotencoder.fit(df[[c1]])\n",
    "            ones_hots[c1] = onehotencoder\n",
    "        else:\n",
    "            onehotencoder = ones_hots[c1]\n",
    "        \n",
    "        M = pd.DataFrame(onehotencoder.transform(df[[c1]]).toarray())\n",
    "            \n",
    "        num_cols = len(list(M))\n",
    "        rng = range(0, num_cols)\n",
    "        new_cols = [c1 + str(i) for i in rng] \n",
    "        M.columns = new_cols[:num_cols]\n",
    "        return M\n",
    "\n",
    "    categorical = pd.concat([crearOneHotDF(i) for i in categoric_cols], axis=1)\n",
    "\n",
    "    df = pd.concat([categorical, df[numeric_cols], df[numeric_cols_2], df[date_cols]], axis=1)\n",
    "    \n",
    "    df = df.sort_values(by=\"Opportunity_Created_Date\")\n",
    "    \n",
    "    df = df.drop(columns = 'Opportunity_Created_Date')\n",
    "    df = df.drop(columns = 'Account_Created_Date')\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/usr/src/tp2-1/Train_TP2_Datos_2020-2C.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region', 'Territory', 'Bureaucratic_Code', 'Source ', 'Billing_Country', 'Account_Name', 'Account_Owner', 'Opportunity_Owner', 'Account_Type', 'Opportunity_Type', 'Delivery_Terms', 'Brand', 'Product_Type', 'Size', 'Product_Category_B', 'Price', 'Currency', 'Quote_Expiry_Date', 'Last_Modified_Date', 'Last_Modified_By', 'Product_Family', 'Product_Name', 'ASP_Currency', 'ASP_(converted)_Currency', 'Month', 'Delivery_Quarter', 'Actual_Delivery_Date', 'Total_Amount_Currency', 'Total_Taxable_Amount_Currency', 'Prod_Category_A']\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "ones_hots = {}\n",
    "ndf = normaliza_df(df_train, ones_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16947, 4517)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.to_csv('/usr/src/tp2-1/210215_tp2_train_feng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/usr/src/tp2-1/Test_TP2_Datos_2020-2C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region', 'Territory', 'Bureaucratic_Code', 'Source ', 'Billing_Country', 'Account_Name', 'Account_Owner', 'Opportunity_Owner', 'Account_Type', 'Opportunity_Type', 'Delivery_Terms', 'Brand', 'Product_Type', 'Size', 'Product_Category_B', 'Price', 'Currency', 'Quote_Expiry_Date', 'Last_Modified_Date', 'Last_Modified_By', 'Product_Family', 'Product_Name', 'ASP_Currency', 'ASP_(converted)_Currency', 'Month', 'Delivery_Quarter', 'Actual_Delivery_Date', 'Total_Amount_Currency', 'Total_Taxable_Amount_Currency', 'Prod_Category_A']\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "ndft = normaliza_df(df_test, ones_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551, 4516)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndft.to_csv('/usr/src/tp2-1/210215_tp2_test_feng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
