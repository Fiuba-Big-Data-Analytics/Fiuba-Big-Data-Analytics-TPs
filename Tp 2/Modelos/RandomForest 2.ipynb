{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def normaliza_df(df, onehotencoder = None):\n",
    "    print(df.shape)\n",
    "\n",
    "    # drops -------------------------------------------------\n",
    "    '''\n",
    "      removemos la columna de la cual el modelo podria aprender que su existencia\n",
    "      implica el Closed_won (ya que es un valor que se obtiene a posteriori de haber\n",
    "      ganado y estaria mal usarlo ya que los modelos entrenadas con ella serian \n",
    "      incapaces de poder predecir correctamente)\n",
    "    '''\n",
    "    df = df.drop(['Sales_Contract_No'], axis=1)\n",
    "    \n",
    "    # irrelevantes (se eliminan) ----------------------------------------------\n",
    "    \n",
    "    # Total_Taxable_Amount = Sum rows[Total_Amount]\n",
    "    \n",
    "    # preparamos la columna Total_Taxable_Amount para ser aplanada\n",
    "    df[\"Total_Amount_sum\"] = df.groupby(\"Opportunity_ID\")[\"Total_Amount\"].transform(\"sum\")\n",
    "\n",
    "    df = df.drop(['Total_Taxable_Amount'], axis=1)\n",
    "    df = df.drop(['Total_Amount_Currency'], axis=1)\n",
    "\n",
    "    \n",
    "    # esta columna es equivalente a oportunity_id\n",
    "    df = df.drop(['Opportunity_Name'], axis=1)\n",
    "    \n",
    "    # dato cte = NaT\n",
    "    df = df.drop(['Last_Activity'], axis=1)\n",
    "    \n",
    "    # todo: convertir estas en una ventana de tiempo\n",
    "    df['Planned_Delivery_Start_Date'] = pd.to_datetime(df['Planned_Delivery_Start_Date'], format=\"%m/%d/%Y\")\n",
    "    df['Planned_Delivery_End_Date'] = pd.to_datetime(df['Planned_Delivery_End_Date'], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    df['Planned_Delivery_Date_diff'] = (df['Planned_Delivery_End_Date'] - df['Planned_Delivery_Start_Date']).dt.days\n",
    "    \n",
    "    df = df.drop(['Planned_Delivery_Start_Date'], axis=1)\n",
    "    df = df.drop(['Planned_Delivery_End_Date'], axis=1)\n",
    "    \n",
    "    # @todo: no estoy seguro si esto aporta\n",
    "    df = df.drop(['Quote_Expiry_Date'], axis=1)\n",
    "    \n",
    "    # @todo: convertirla a una diferencia de dias?\n",
    "    df = df.drop(['Last_Modified_Date'], axis=1)\n",
    "    \n",
    "    # @todo: existe Opportunity_id \n",
    "    df = df.drop(['ID'], axis=1)\n",
    "\n",
    "    # basado en lo charlado con el grupo, ahora subdividimos el df de forma de tener\n",
    "    # en cuenta los casos cerrados y cobertimos las varaibles categorias en su\n",
    "    # representacion mas simple (siendo dos casos en Cloased_Won = 1 y Closed:_lost = 0)\n",
    "    if 'Stage' in df.columns:\n",
    "        df = df[((df['Stage'] == 'Closed Won') | (df['Stage'] == 'Closed Lost'))]\n",
    "        df['Stage'] = df['Stage'].apply(lambda x: 1 if x == 'Closed Won' else 0)\n",
    "    \n",
    "    # hacemos que las variables temporales en las que nos vanos a enfocar sean del tipo correcto\n",
    "    df['Account_Created_Date'] = pd.to_datetime(df['Account_Created_Date'], format=\"%m/%d/%Y\")\n",
    "    df['Opportunity_Created_Date'] = pd.to_datetime(df['Opportunity_Created_Date'], format=\"%m/%d/%Y\")\n",
    "    \n",
    "    df['Quote_Type'] = df['Quote_Type'].apply(lambda x: 1 if x == 'Binding' else 0)\n",
    "    \n",
    "    #------------------------------------------\n",
    "    df = df.sort_values(by=\"Opportunity_Created_Date\")\n",
    "    \n",
    "    df = df.drop(columns = 'Opportunity_Created_Date')\n",
    "    df = df.drop(columns = 'Account_Created_Date')\n",
    "    #------------------------------------------\n",
    "    \n",
    "    categoric_cols = df.columns[df.dtypes==object].tolist() \n",
    "    numeric_cols = df.columns[df.dtypes=='float64'].tolist() \n",
    "    numeric_cols_2 = df.columns[df.dtypes=='int64'].tolist() \n",
    "    date_cols = df.columns[df.dtypes=='datetime64[ns]'].tolist() \n",
    "\n",
    "    if 'Stage' in df.columns:\n",
    "        onehotencoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "        onehotencoder.fit(df[categoric_cols])\n",
    "    \n",
    "    cat_rel = 0\n",
    "    all_col_names = []\n",
    "    for cat in onehotencoder.categories_:\n",
    "        for col in cat:\n",
    "            all_col_names.append(categoric_cols[cat_rel] + '_' + col)\n",
    "        cat_rel = cat_rel + 1\n",
    "    \n",
    "    categorical = pd.DataFrame(onehotencoder.transform(df[categoric_cols]).toarray(), columns=all_col_names)\n",
    "    \n",
    "    categorical = categorical.reset_index()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    print('ante ...')\n",
    "    print(df.shape)\n",
    "    print(categorical.shape)\n",
    "    print(df[numeric_cols].shape)\n",
    "    print(df[numeric_cols_2].shape)\n",
    "\n",
    "    frames_to_concat = [categorical, df[numeric_cols], df[numeric_cols_2]]\n",
    "    df_r =  pd.concat(frames_to_concat, axis=1)\n",
    "       \n",
    "    df_r = df_r.drop(columns = 'index')\n",
    "    \n",
    "    return df_r, onehotencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_binary =  pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Fiuba-Big-Data-Analytics-TPs/Tp 2/Datos/TrainBinaryEncoding.csv')\n",
    "test_binary =  pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Fiuba-Big-Data-Analytics-TPs/Tp 2/Datos/TestBinaryEncoding.csv')\n",
    "\n",
    "test_binary = test_binary.drop(columns =\"Unnamed: 0\")\n",
    "train_binary = train_binary.drop(columns =\"Unnamed: 0\")\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(train_binary.drop(columns = 'Stage'), train_binary['Stage'], test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.268029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.91, 0.04, 1.  , ..., 0.25, 0.57, 0.97])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_r = RandomForestRegressor(random_state = 0)\n",
    "model_r.fit(X_train, y_train)\n",
    "predict_r = model_r.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predict_r))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "predict_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.260197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12, 0.88],\n",
       "       [0.95, 0.05],\n",
       "       [0.  , 1.  ],\n",
       "       ...,\n",
       "       [0.82, 0.18],\n",
       "       [0.84, 0.16],\n",
       "       [0.01, 0.99]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r2 = RandomForestClassifier(random_state = 0)\n",
    "model_r2.fit(X_train, y_train)\n",
    "predict_r2 = model_r2.predict_proba(X_test)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test, predict_r2[:,1]))\n",
    "print(\"RMSE: %f\" % (rmse2))\n",
    "\n",
    "predict_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5 , 0.5 ],\n",
       "       [0.39, 0.61],\n",
       "       [0.34, 0.66],\n",
       "       ...,\n",
       "       [0.48, 0.52],\n",
       "       [0.39, 0.61],\n",
       "       [0.7 , 0.3 ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model_r2.predict_proba(test_binary.fillna(0))\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opportunity_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>0.593333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12365</th>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Target\n",
       "Opportunity_ID          \n",
       "10689           0.590000\n",
       "10690           0.518000\n",
       "10691           0.660000\n",
       "10692           0.593333\n",
       "10693           0.780000\n",
       "...                  ...\n",
       "12364           0.610000\n",
       "12365           0.580000\n",
       "12366           0.520000\n",
       "12367           0.610000\n",
       "12368           0.300000\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Opportunity_ID':test_binary.Opportunity_ID, 'Target': predicts[:,1]})\n",
    "output = output.groupby('Opportunity_ID').mean()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Fiuba-Big-Data-Analytics-TPs/Tp 2/Datos/Test_TP2_Datos_2020-2C.csv')\n",
    "\n",
    "train = pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Fiuba-Big-Data-Analytics-TPs/Tp 2/Datos/Train_TP2_Datos_2020-2C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16947, 52)\n",
      "ante ...\n",
      "(16883, 43)\n",
      "(16883, 2853)\n",
      "(16883, 5)\n",
      "(16883, 10)\n",
      "(2551, 51)\n",
      "ante ...\n",
      "(2551, 42)\n",
      "(2551, 2853)\n",
      "(2551, 5)\n",
      "(2551, 9)\n"
     ]
    }
   ],
   "source": [
    "[train_onehot, one_hot] = normaliza_df(train)\n",
    "[test_onehot, _] = normaliza_df(test, one_hot)\n",
    "\n",
    "train_onehot =train_onehot.fillna(0)\n",
    "test_onehot = test_onehot.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(train_onehot.drop(columns = 'Stage'), train_onehot['Stage'], test_size=0.2, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.249198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15, 0.85],\n",
       "       [0.01, 0.99],\n",
       "       [0.16, 0.84],\n",
       "       ...,\n",
       "       [0.25, 0.75],\n",
       "       [0.87, 0.13],\n",
       "       [0.86, 0.14]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r2 = RandomForestClassifier(random_state = 0)\n",
    "model_r2.fit(X_train, y_train)\n",
    "predict_r2 = model_r2.predict_proba(X_test)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test, predict_r2[:,1]))\n",
    "print(\"RMSE: %f\" % (rmse2))\n",
    "\n",
    "predict_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34, 0.66],\n",
       "       [0.17, 0.83],\n",
       "       [0.19, 0.81],\n",
       "       ...,\n",
       "       [0.3 , 0.7 ],\n",
       "       [0.42, 0.58],\n",
       "       [0.7 , 0.3 ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model_r2.predict_proba(test_onehot)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opportunity_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>0.634000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>0.751667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12365</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Target\n",
       "Opportunity_ID          \n",
       "10689           0.680000\n",
       "10690           0.634000\n",
       "10691           0.730000\n",
       "10692           0.751667\n",
       "10693           0.930000\n",
       "...                  ...\n",
       "12364           0.770000\n",
       "12365           0.700000\n",
       "12366           0.580000\n",
       "12367           0.600000\n",
       "12368           0.300000\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Opportunity_ID':test_onehot.Opportunity_ID, 'Target': predicts[:,1]})\n",
    "output = output.groupby('Opportunity_ID').mean()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivos de fernando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fer = pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Datos Pesados/210227_tp2_test_feng.csv')\n",
    "train_fer = pd.read_csv('/home/leandro/Documentos/Organizacion de datos/Datos Pesados/210227_tp2_train_feng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(train_fer.drop(columns = 'Stage'), train_fer['Stage'], test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.316260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21, 0.79],\n",
       "       [0.83, 0.17],\n",
       "       [0.62, 0.38],\n",
       "       ...,\n",
       "       [0.05, 0.95],\n",
       "       [1.  , 0.  ],\n",
       "       [0.67, 0.33]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r2 = RandomForestClassifier(random_state = 0)\n",
    "model_r2.fit(X_train, y_train)\n",
    "predict_r2 = model_r2.predict_proba(X_test)\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test, predict_r2[:,1]))\n",
    "print(\"RMSE: %f\" % (rmse2))\n",
    "\n",
    "predict_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39, 0.61],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.26, 0.74],\n",
       "       ...,\n",
       "       [0.56, 0.44],\n",
       "       [0.42, 0.58],\n",
       "       [0.81, 0.19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model_r2.predict_proba(test_fer)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Opportunity_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10693</th>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12364</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12365</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12367</th>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368</th>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Target\n",
       "Opportunity_ID        \n",
       "10689             0.61\n",
       "10690             0.50\n",
       "10691             0.74\n",
       "10692             0.57\n",
       "10693             0.83\n",
       "...                ...\n",
       "12364             0.75\n",
       "12365             0.54\n",
       "12366             0.44\n",
       "12367             0.58\n",
       "12368             0.19\n",
       "\n",
       "[1567 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Opportunity_ID':test_fer.Opportunity_ID, 'Target': predicts[:,1]})\n",
    "output = output.groupby('Opportunity_ID').max()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('/home/leandro/Documentos/Organizacion de datos/Fiuba-Big-Data-Analytics-TPs/Tp 2/Resultados/RandomForestScore4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
